{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pytorch — фреймворк для обучения нейронных сетей и не только"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Зачем нужны библиотеки для обучения нейронных сетей?\n",
    "\n",
    "* иметь качественные и эффективные реализации лоссов, слоев, оптимизаторов\n",
    "* стандартизация кода, использование сторонних библиотек/моделей/имплементаций статей от коммьюнити\n",
    "* ускорение с помощью GPU без написания специального кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Как обучаюся нейронные сети?\n",
    "\n",
    "- методы оптимизации, использующие градиент\n",
    "\n",
    "- для оптимизации вычисления градиента используют метод обратного распространения ошибки\n",
    "\n",
    "Поэтому в основе любого фреймворка лежит автоматическое дифференцирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Фреймворки\n",
    "\n",
    "Динамика популярности по поисковым запросам в Google:\n",
    "\n",
    "![](images/frameworks.png)\n",
    "\n",
    "Tensorflow и Pytorch — два основных фреймворка на текущий момент. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## В чём разница?\n",
    "\n",
    "- Все фреймворки содержат приблизительно одинаковый функционал: модули для построения сетей, оптимизаторы для настройки, полезные утили, ...\n",
    "\n",
    "- Tensorflow 1 использует статическое определение графа (сначала указанный граф компилируется, а потом через него можно прогонять данные).\n",
    "\n",
    "- Pytorch и новый Tensorflow 2 используют динамическое определение графа — не нужно строить граф заранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## На практике\n",
    "\n",
    "- Динамическое построение графа — привычная работа в python-парадигме и удобная отладка на ходу.\n",
    "\n",
    "- На практике стоит немного понимать все популярные фреймворки — приходится изучать и использовать открытые реализации по свежим статьям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pytorch\n",
    "\n",
    "### Tensors\n",
    "\n",
    "Тензор — многомерный массив и основной объект в Pytorch. Операции с тензорами происходят почти также, как и с массивами в numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:33.425651Z",
     "start_time": "2019-10-25T15:29:33.212665Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:34.219304Z",
     "start_time": "2019-10-25T15:29:34.214590Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.Tensor()\n",
    "\n",
    "print(x, x.type())\n",
    "print(\"Tensor's device: \", x.device)\n",
    "\n",
    "# x.to(\"cuda\")  # выдаст ошибку на машине без настроенной CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:34.839089Z",
     "start_time": "2019-10-25T15:29:34.833487Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Создание тензора \"из данных\"\n",
    "\n",
    "# np.array([10., 20., 30.])\n",
    "\n",
    "x = torch.tensor([10., 20., 30.])  \n",
    "print(f\"I'm {x}, my type is {x.type()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:35.340219Z",
     "start_time": "2019-10-25T15:29:35.336100Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Дополнительно мы можем указать тип тензора с помощью dtype\n",
    "\n",
    "# np.array([10., 20., 30.], dtype=np.int32)\n",
    "\n",
    "x = torch.tensor([10., 20., 30.], dtype=torch.long)  \n",
    "print(f\"I'm {x}, my type is {x.type()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:35.755618Z",
     "start_time": "2019-10-25T15:29:35.750995Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Мы можем создать тензор из np.ndarray\n",
    "\n",
    "numpy_arr = np.eye(4)\n",
    "x = torch.from_numpy(numpy_arr)\n",
    "print(f\"I'm {x}, my type is {x.type()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:36.100692Z",
     "start_time": "2019-10-25T15:29:36.096426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Метод from_numpy не создает тензор, он использает тот же участок памяти, что и массив. \n",
    "# Поэтому изменив массив -- мы изменим тензор.\n",
    "\n",
    "numpy_arr[:, 0] = 50\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:36.483470Z",
     "start_time": "2019-10-25T15:29:36.475123Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Можно создавать тензоры и без данных. \n",
    "\n",
    "# Ниже несколько примеров, которые почти эквивалентны соответствующим в numpy\n",
    "x = torch.rand(3,3) # np.random.rand(3,3)\n",
    "print(f\"Random tensor {x}\")\n",
    "x = torch.eye(3) # np.eye(3)\n",
    "print(f\"Identity tensor {x}\")\n",
    "x = torch.ones(4, 5) # np.ones((4,5))\n",
    "print(f\"All-ones tensor {x}\")\n",
    "x = torch.zeros(4, 5) # np.zeros((4,5))\n",
    "print(f\"All-zeros tensor {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:36.874272Z",
     "start_time": "2019-10-25T15:29:36.851730Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Pytorch умеет превращать тензор в numpy ndarray\n",
    "\n",
    "x = torch.rand(2, 2)\n",
    "x_np = x.numpy()\n",
    "print(f\"I'm {x_np}, my type is {type(x_np)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:37.256558Z",
     "start_time": "2019-10-25T15:29:37.252487Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Размер тензора можно узнать с помощью .size(), .shape\n",
    "\n",
    "x = torch.rand(2, 2)\n",
    "print(\"x.shape: \", x.shape, \"\\nx.size(): \", x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:37.573561Z",
     "start_time": "2019-10-25T15:29:37.564984Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Менять размер тензора можно с помощью .view([s_1, s_2, s_3, ..., s_n]).\n",
    "# Произведение  s_1 * ... * s_n -- должно быть равно количеству элементов.\n",
    "# Одну из s_i можно заменить на -1, тогда она рассчитается автоматически\n",
    "\n",
    "x = torch.arange(12)\n",
    "print(x.view([2, 6]).numpy())\n",
    "print(x.view([3, -1]).numpy()) \n",
    "print(x.view([2, 3, -1]).numpy())\n",
    "try:\n",
    "    print(x.view([2, 5]).numpy())\n",
    "except RuntimeError as e:\n",
    "    print(f\"Wrong dimentions produce the following error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:37.835406Z",
     "start_time": "2019-10-25T15:29:37.827562Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# В заключении этого блока покажем, что изменять значение тензора можно прямым обращением по индексу.\n",
    "\n",
    "x = torch.arange(25).view((-1, 5))\n",
    "print(x)\n",
    "print(x[2,4])\n",
    "print(x[2])\n",
    "print(x[[0,1,2,3], 0])\n",
    "x[[0,1,2,3,4], 0] = 100\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Операции над тензорами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:38.426102Z",
     "start_time": "2019-10-25T15:29:38.413415Z"
    }
   },
   "outputs": [],
   "source": [
    "# Операции над тензорами производятся интуитивно понятно.\n",
    "# Разберем это на примере двуслойной сети и подсчета \n",
    "# лосса -- среднеквадратичного отклонения\n",
    "\n",
    "batch_size = 3\n",
    "n_features = 10\n",
    "H_n = 30\n",
    "\n",
    "# сначала создадим все необходимые тензоры -- рандомный вход, выход и веса. Это делать мы уже умеем )\n",
    "\n",
    "y_real = torch.rand(batch_size)\n",
    "x = torch.rand(batch_size, n_features)\n",
    "\n",
    "w_1 = torch.rand(n_features, H_n)\n",
    "b_1 = torch.rand(H_n)\n",
    "\n",
    "w_2 = torch.rand(H_n, 1)\n",
    "b_2 = torch.rand(1)\n",
    "\n",
    "y_h_1 = (x.matmul(w_1) + b_1).clamp(min=0)  # relu\n",
    "y_pred = y_h_1.matmul(w_2)+b_2\n",
    "print('Predictions:')\n",
    "print(y_pred)\n",
    "\n",
    "loss = (y_pred - y_real).pow(2).sum()\n",
    "print('Loss:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Автодифференцирование\n",
    "\n",
    "Разберёмся, как выглядит автодифференцирование на практике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:39.146791Z",
     "start_time": "2019-10-25T15:29:39.139800Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.tensor(2.)\n",
    "b = torch.tensor(1.)\n",
    "\n",
    "c = a + b\n",
    "d = b + 1\n",
    "e = c * d\n",
    "\n",
    "print(a, b, c, d, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Мы можем представить это в виде следующего графа:\n",
    "<img src=\"images/tree-eval.png\" width=\"600\">\n",
    "\n",
    "Тепрь посчитаем частные производные по $a$ и $b$.\n",
    "$$\\frac{\\partial e}{\\partial a} = \\frac{\\partial e}{\\partial c} \\frac{\\partial c}{\\partial a}$$\n",
    "$$\\frac{\\partial e}{\\partial b} = \\frac{\\partial e}{\\partial c} \\frac{\\partial c}{\\partial b} + \n",
    "\\frac{\\partial e}{\\partial d} \\frac{\\partial d}{\\partial b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Можно заметить, что, считая поизводные мы спускаемся про графу сверху вниз, считая производные одного узла по соседнему.\n",
    "\n",
    "<img src=\"images/tree-eval-derivs.png\" width=\"600\">\n",
    "\n",
    "- $\\frac{\\partial e}{\\partial a}$ равна произведению значений на ребрах по пути из $a$ в $e$.\n",
    "- Из $b$ в $e$ идет два пути, и в формуле выше мы видим что мы суммируем значения, полученные для каждого из путей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Подробнее про бэкпроп: http://colah.github.io/posts/2015-08-Backprop/\n",
    "\n",
    "Как автоград устроен в Pytorch: https://youtu.be/MswxJw-8PvE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Чтобы посчитать градиент в Pytorch, нужно обратиться к полю .grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:40.783866Z",
     "start_time": "2019-10-25T15:29:40.777592Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(1., requires_grad=True)\n",
    "\n",
    "c = a + b\n",
    "d = b + 1\n",
    "e = c * d\n",
    "e.backward()\n",
    "\n",
    "print(\"de/da = \", a.grad.item(), \"de/db = \", b.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:41.099353Z",
     "start_time": "2019-10-25T15:29:41.094410Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "c.backward()\n",
    "\n",
    "print(\"dc/da = \", a.grad.item(), \"dc/db = \", b.grad.item())\n",
    "\n",
    "# Почему это неправильно?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:41.412158Z",
     "start_time": "2019-10-25T15:29:41.407204Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# zero gradients !\n",
    "\n",
    "a.grad.data.zero_()\n",
    "b.grad.data.zero_()\n",
    "c.backward()\n",
    "\n",
    "print(\"dc/da = \", a.grad.item(), \"dc/db = \", b.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:41.700034Z",
     "start_time": "2019-10-25T15:29:41.693611Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Теперь напишем бекпроп и зафитим случайную выборку )\n",
    "# источник: https://github.com/jcjohnson/pytorch-examples\n",
    "\n",
    "# Лучше сразу задавать переменную device, чтобы не переписывать потом\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# N размер бача; D_in размер кода;\n",
    "# H размер скрытого слоя; D_out размер выхода\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Создадим случайную выборку\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "# Инициализируем веса сети\n",
    "w1 = torch.randn(D_in, H, device=device, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:42.117321Z",
     "start_time": "2019-10-25T15:29:41.994471Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(100):\n",
    "    \n",
    "    # Прямой проход\n",
    "    y_pred = (x.mm(w1).clamp(min=0)).mm(w2)\n",
    "    \n",
    "    # Считаем средне-квадратичное отклонение -- лосс\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "    \n",
    "    # Считаем производные по параметрам \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Градиентный спуск\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Зануляем градиенты\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## torch.nn, torch.optim\n",
    "\n",
    "Удобство библиотеки не ограничивается одним только автодифференцированием. Многое из того что мы написали выше уже реализовано.\n",
    "\n",
    "В частности, стандартные слои, функции активаций, лоссы, оптимизаторы. Вот как выгдядит упрощенная версия кода, использующая модуль torch.nn и torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:42.939294Z",
     "start_time": "2019-10-25T15:29:42.933245Z"
    }
   },
   "outputs": [],
   "source": [
    "# В моделе класса Sequential операции выполняются одна за другой. \n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),  # мы не определяем параметры сами -- за это отвечает модель\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "for name, parameter in model.named_parameters():\n",
    "    print(name, parameter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:43.433924Z",
     "start_time": "2019-10-25T15:29:43.236117Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for t in range(100):\n",
    "    \n",
    "    # Прямой проход\n",
    "    y_pred = model(x)\n",
    "\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Обратный проход\n",
    "    loss.backward()\n",
    "\n",
    "    # Шаг оптимизации\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## nn.Module, nn.Dataset\n",
    "\n",
    "<img src=\"images/fashion-mnist-sprite.png\" width=\"600\">\n",
    "</br>\n",
    "\n",
    "Теперь попробуем обучить классификатор одежды для датасета FashionMNIST (https://github.com/zalandoresearch/fashion-mnist ). \n",
    "\n",
    "Основные новые концепции, которые мы усвоим на этом примере — **Dataset,  Dataloader, Model**. Они необходимы для удобной работы с библиотекой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:59.003799Z",
     "start_time": "2019-10-25T15:29:58.938009Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import download_mnist, save_mnist, load\n",
    "from pathlib import Path\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:29:59.919020Z",
     "start_time": "2019-10-25T15:29:59.910616Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Начнем с класса Dataset. По названию можно догадаться, что он нужен для работы с датасетами\n",
    "# Это очень удобная абстракция, которая в дальнейшем может быть использована в комбинации с \n",
    "# Dataloader, для параллельной загрузки данных. Но об этом позже.\n",
    "\n",
    "# Кастомный датасет должен переопределить два метода: __len__ и __getitem__. \n",
    "\n",
    "class FashionMNISTDataset(Dataset):\n",
    "    def __init__(self, transforms=None, training=True):\n",
    "        if not Path(\"mnist.pkl\").exists():\n",
    "            download_mnist()\n",
    "            save_mnist()\n",
    "        train_imgs, train_labels, test_imgs, test_labels = load()\n",
    "        self.training = training\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        if self.training:\n",
    "            self.imgs = train_imgs\n",
    "            self.labels = train_labels\n",
    "        else:\n",
    "            self.imgs = test_imgs\n",
    "            self.labels = test_labels\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx].reshape((-1, 28, 1))\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img, torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:05.365094Z",
     "start_time": "2019-10-25T15:30:00.456267Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "    'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "data_transformation = transforms.Compose([transforms.ToTensor()])\n",
    "datasets = {\n",
    "    x: FashionMNISTDataset(\n",
    "        training=(x == \"train\"), \n",
    "        transforms=data_transformation) for x in [\"train\", \"test\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:05.622149Z",
     "start_time": "2019-10-25T15:30:05.367153Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "image, label = datasets[\"train\"][1]\n",
    "print(image.shape, label)\n",
    "plt.title(classes[label.numpy()])\n",
    "plt.imshow(image.numpy().squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:05.636793Z",
     "start_time": "2019-10-25T15:30:05.623689Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# DataLoader это python iterable, который возвращает элементы Dataset бачами\n",
    "\n",
    "dataloaders = {\n",
    "    x: DataLoader(datasets[x], batch_size=10, shuffle=True, num_workers=0)\n",
    "    for x in [\"train\", \"test\"]}\n",
    "batch = next(iter(dataloaders[\"train\"]))\n",
    "images, labels = batch\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:06.620663Z",
     "start_time": "2019-10-25T15:30:06.280629Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(images, nrow=10)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "\n",
    "print('labels:', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:06.709976Z",
     "start_time": "2019-10-25T15:30:06.701795Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Модели в питорче наследуются от nn.Module\n",
    "# В стандартном случае нужно определить только __init__ для описания\n",
    "# состовляющих частей архитектуры и forward для определения того, \n",
    "# как они должны взаимодействовать при прямом проходе\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7 * 7 * 32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:07.208479Z",
     "start_time": "2019-10-25T15:30:07.200479Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model = Network().to(device)\n",
    "print(model)\n",
    "print(\"\\nModel parameters shapes:\")\n",
    "for name, parameter in model.named_parameters():\n",
    "    print(name, parameter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:07.641391Z",
     "start_time": "2019-10-25T15:30:07.635183Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, n_epoch):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        for batch_id, (image, label) in enumerate(dataloader):\n",
    "            label, image = label.to(device), image.to(device)\n",
    "            output = model(image)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_id % 1000 == 0:\n",
    "                print('Loss :{:.4f} Epoch[{}/{}]'.format(loss.item(), epoch, n_epoch))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:33.873460Z",
     "start_time": "2019-10-25T15:30:08.434838Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "n_epoch = 5\n",
    "dataloaders = {\n",
    "    x: DataLoader(datasets[x], batch_size=1000, shuffle=x == \"train\")\n",
    "    for x in [\"train\", \"test\"]}\n",
    "\n",
    "model = train(model, dataloader=dataloaders[\"train\"], n_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:33.875430Z",
     "start_time": "2019-10-25T15:30:08.788Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def test(model, dataloader):\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for image, label in dataloader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(image)\n",
    "            predicted = torch.argmax(outputs,dim=1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            targets.extend(label.cpu().numpy())\n",
    "            \n",
    "        \n",
    "    predictions = np.array(predictions)\n",
    "    targets = np.array(targets)\n",
    "    print(f\"Test Accuracy of the model on the test images: {accuracy_score(targets, predictions)*100} %\")\n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:33.876280Z",
     "start_time": "2019-10-25T15:30:09.168Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "predictions, targets = test(model, dataloaders[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:33.877341Z",
     "start_time": "2019-10-25T15:30:09.560Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ids = np.where((np.array(predictions) != np.array(targets)))[0]\n",
    "num = 310\n",
    "image, label = datasets[\"test\"][ids[num]]\n",
    "print(image.shape, label)\n",
    "plt.title(f\"Real: {classes[targets[ids[num]]]}. Predicted: {classes[predictions[ids[num]]]}\")\n",
    "plt.imshow(image.numpy().squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T15:30:33.878568Z",
     "start_time": "2019-10-25T15:30:10.017Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from utils import plot_confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(targets, predictions)\n",
    "plot_confusion_matrix(cm, classes, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "dmia2019",
   "language": "python",
   "name": "dmia2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
